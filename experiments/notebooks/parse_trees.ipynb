{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe81752a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset, load_from_disk, DatasetDict, concatenate_datasets\n",
    "import numpy as np\n",
    "from scipy.sparse.csgraph import floyd_warshall\n",
    "from transformers import DataCollatorWithPadding\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "546b2de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset universal_dependencies (/users/ujan/.cache/huggingface/datasets/universal_dependencies/en_ewt/2.7.0/1ac001f0e8a0021f19388e810c94599f3ac13cc45d6b5b8c69f7847b2188bdf7)\n",
      "Found cached dataset universal_dependencies (/users/ujan/.cache/huggingface/datasets/universal_dependencies/en_ewt/2.7.0/1ac001f0e8a0021f19388e810c94599f3ac13cc45d6b5b8c69f7847b2188bdf7)\n",
      "Found cached dataset universal_dependencies (/users/ujan/.cache/huggingface/datasets/universal_dependencies/en_ewt/2.7.0/1ac001f0e8a0021f19388e810c94599f3ac13cc45d6b5b8c69f7847b2188bdf7)\n",
      "Found cached dataset universal_dependencies (/users/ujan/.cache/huggingface/datasets/universal_dependencies/en_gum/2.7.0/1ac001f0e8a0021f19388e810c94599f3ac13cc45d6b5b8c69f7847b2188bdf7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21b6be26b32243f5b21b9e9c15eaaeac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset universal_dependencies (/users/ujan/.cache/huggingface/datasets/universal_dependencies/en_lines/2.7.0/1ac001f0e8a0021f19388e810c94599f3ac13cc45d6b5b8c69f7847b2188bdf7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07904f9a1156469a9e2e815fb591068b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset universal_dependencies (/users/ujan/.cache/huggingface/datasets/universal_dependencies/en_partut/2.7.0/1ac001f0e8a0021f19388e810c94599f3ac13cc45d6b5b8c69f7847b2188bdf7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "796f696ce30a4bedbf970687a497a15f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset universal_dependencies (/users/ujan/.cache/huggingface/datasets/universal_dependencies/en_pronouns/2.7.0/1ac001f0e8a0021f19388e810c94599f3ac13cc45d6b5b8c69f7847b2188bdf7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb048df19b24ec8837b92adad1bad81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset universal_dependencies (/users/ujan/.cache/huggingface/datasets/universal_dependencies/en_pud/2.7.0/1ac001f0e8a0021f19388e810c94599f3ac13cc45d6b5b8c69f7847b2188bdf7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50e419b50489411e92acdd0befa23171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config_list = ['en_gum', 'en_lines', 'en_partut', 'en_pronouns', 'en_pud']\n",
    "dataset = DatasetDict()\n",
    "\n",
    "dataset['train'] = load_dataset('universal_dependencies', 'en_ewt', split='train')\n",
    "dataset['validation'] = load_dataset('universal_dependencies', 'en_ewt', split='validation')\n",
    "dataset['test'] = load_dataset('universal_dependencies', 'en_ewt', split='test')\n",
    "\n",
    "for config in config_list:\n",
    "    data = load_dataset('universal_dependencies', config)\n",
    "    keys = data.keys()\n",
    "    for key in keys:\n",
    "        dataset[key] = concatenate_datasets([dataset[key], data[key]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4035b09c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['idx', 'text', 'tokens', 'lemmas', 'upos', 'xpos', 'feats', 'head', 'deprel', 'deps', 'misc'],\n",
       "        num_rows: 21787\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['idx', 'text', 'tokens', 'lemmas', 'upos', 'xpos', 'feats', 'head', 'deprel', 'deps', 'misc'],\n",
       "        num_rows: 3974\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['idx', 'text', 'tokens', 'lemmas', 'upos', 'xpos', 'feats', 'head', 'deprel', 'deps', 'misc'],\n",
       "        num_rows: 5440\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d5ac94c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idx': 'weblog-blogspot.com_aggressivevoicedaily_20060629164800_ENG_20060629_164800-0008',\n",
       " 'text': 'ALITO filed a dissenting opinion, in which SCALIA and THOMAS joined as to Parts I through III.',\n",
       " 'tokens': ['ALITO',\n",
       "  'filed',\n",
       "  'a',\n",
       "  'dissenting',\n",
       "  'opinion',\n",
       "  ',',\n",
       "  'in',\n",
       "  'which',\n",
       "  'SCALIA',\n",
       "  'and',\n",
       "  'THOMAS',\n",
       "  'joined',\n",
       "  'as',\n",
       "  'to',\n",
       "  'Parts',\n",
       "  'I',\n",
       "  'through',\n",
       "  'III',\n",
       "  '.'],\n",
       " 'lemmas': ['ALITO',\n",
       "  'file',\n",
       "  'a',\n",
       "  'dissent',\n",
       "  'opinion',\n",
       "  ',',\n",
       "  'in',\n",
       "  'which',\n",
       "  'SCALIA',\n",
       "  'and',\n",
       "  'THOMAS',\n",
       "  'join',\n",
       "  'as',\n",
       "  'to',\n",
       "  'part',\n",
       "  'i',\n",
       "  'through',\n",
       "  'iii',\n",
       "  '.'],\n",
       " 'upos': [10, 16, 8, 16, 0, 1, 2, 11, 10, 9, 10, 16, 2, 2, 0, 3, 2, 3, 1],\n",
       " 'xpos': ['NNP',\n",
       "  'VBD',\n",
       "  'DT',\n",
       "  'VBG',\n",
       "  'NN',\n",
       "  ',',\n",
       "  'IN',\n",
       "  'WDT',\n",
       "  'NNP',\n",
       "  'CC',\n",
       "  'NNP',\n",
       "  'VBD',\n",
       "  'IN',\n",
       "  'IN',\n",
       "  'NNS',\n",
       "  'CD',\n",
       "  'IN',\n",
       "  'CD',\n",
       "  '.'],\n",
       " 'feats': [\"{'Number': 'Sing'}\",\n",
       "  \"{'Mood': 'Ind', 'Tense': 'Past', 'VerbForm': 'Fin'}\",\n",
       "  \"{'Definite': 'Ind', 'PronType': 'Art'}\",\n",
       "  \"{'VerbForm': 'Ger'}\",\n",
       "  \"{'Number': 'Sing'}\",\n",
       "  'None',\n",
       "  'None',\n",
       "  \"{'PronType': 'Int'}\",\n",
       "  \"{'Number': 'Sing'}\",\n",
       "  'None',\n",
       "  \"{'Number': 'Sing'}\",\n",
       "  \"{'Mood': 'Ind', 'Tense': 'Past', 'VerbForm': 'Fin'}\",\n",
       "  'None',\n",
       "  'None',\n",
       "  \"{'Number': 'Plur'}\",\n",
       "  \"{'NumType': 'Card'}\",\n",
       "  'None',\n",
       "  \"{'NumType': 'Card'}\",\n",
       "  'None'],\n",
       " 'head': ['2',\n",
       "  '0',\n",
       "  '5',\n",
       "  '5',\n",
       "  '2',\n",
       "  '5',\n",
       "  '8',\n",
       "  '12',\n",
       "  '12',\n",
       "  '11',\n",
       "  '9',\n",
       "  '5',\n",
       "  '15',\n",
       "  '13',\n",
       "  '12',\n",
       "  '15',\n",
       "  '18',\n",
       "  '16',\n",
       "  '2'],\n",
       " 'deprel': ['nsubj',\n",
       "  'root',\n",
       "  'det',\n",
       "  'amod',\n",
       "  'obj',\n",
       "  'punct',\n",
       "  'case',\n",
       "  'obl',\n",
       "  'nsubj',\n",
       "  'cc',\n",
       "  'conj',\n",
       "  'acl:relcl',\n",
       "  'case',\n",
       "  'fixed',\n",
       "  'obl',\n",
       "  'compound',\n",
       "  'case',\n",
       "  'nmod',\n",
       "  'punct'],\n",
       " 'deps': [\"[('nsubj', 2)]\",\n",
       "  \"[('root', 0)]\",\n",
       "  \"[('det', 5)]\",\n",
       "  \"[('amod', 5)]\",\n",
       "  \"[('obj', 2), ('obl', 12)]\",\n",
       "  \"[('punct', 5)]\",\n",
       "  \"[('case', 8)]\",\n",
       "  \"[('ref', 5)]\",\n",
       "  \"[('nsubj', 12)]\",\n",
       "  \"[('cc', 11)]\",\n",
       "  \"[('conj:and', 9), ('nsubj', 12)]\",\n",
       "  \"[('acl:relcl', 5)]\",\n",
       "  \"[('case', 15)]\",\n",
       "  \"[('fixed', 13)]\",\n",
       "  \"[('obl:as_to', 12)]\",\n",
       "  \"[('compound', 15)]\",\n",
       "  \"[('case', 18)]\",\n",
       "  \"[('nmod:through', 16)]\",\n",
       "  \"[('punct', 2)]\"],\n",
       " 'misc': ['None',\n",
       "  'None',\n",
       "  'None',\n",
       "  'None',\n",
       "  \"{'SpaceAfter': 'No'}\",\n",
       "  'None',\n",
       "  'None',\n",
       "  'None',\n",
       "  'None',\n",
       "  'None',\n",
       "  'None',\n",
       "  'None',\n",
       "  'None',\n",
       "  'None',\n",
       "  'None',\n",
       "  'None',\n",
       "  'None',\n",
       "  \"{'SpaceAfter': 'No'}\",\n",
       "  'None']}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'][56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e31c96c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['idx', 'text', 'tokens', 'lemmas', 'upos', 'xpos', 'feats', 'head', 'deprel', 'deps', 'misc'],\n",
       "    num_rows: 16830\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenate_datasets([dataset['train'], data['train']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "688a6307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'train' in dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e58452f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, XLMRobertaModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
    "#model = XLMRobertaModel.from_pretrained('xlm-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8a32f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['idx', 'text', 'tokens', 'lemmas', 'upos', 'xpos', 'feats', 'head', 'deprel', 'deps', 'misc'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8e55d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = dataset['test'][10]['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72214ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs = tokenizer(\n",
    "    tokens, truncation=True,\n",
    "    max_length=256,\n",
    "    is_split_into_words=True)\n",
    "len(model_inputs['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bfce0abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [id for id in model_inputs.word_ids(0) if id is not None]\n",
    "len(set(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adefa0be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['test'][10]['head'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ac31c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['test'][10]['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7cbd5c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'true_dist'],\n",
       "        num_rows: 993\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_from_disk('/users/ujan/linguistic-structures/data/processed/UD/en_pud_node_distance')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3e2ee2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset['test'][0]['input_ids'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b999b1a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = [1,2,3]\n",
    "np.array(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8fc058e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset['test'][0]['true_dist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0c6e83c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['test'][1]['true_dist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b32bc9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['test'][0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d19361dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset['test'][0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7dbf5280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['test'][1]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dea121fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset['test'][1]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1b7ef6a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset['test'][1]['true_dist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "985b9905",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True, return_tensors='pt')\n",
    "\n",
    "# data loader\n",
    "dataloader = DataLoader(\n",
    "    dataset[\"test\"],\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=16,\n",
    ")\n",
    "\n",
    "#batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "caa53c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`true_dist` in this case) have excessive nesting (inputs type `list` where type `int` is expected).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/Users/ujan/opt/anaconda3/envs/x-transfer/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:715\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor(value):\n\u001b[0;32m--> 715\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;66;03m# Removing this for now in favor of controlling the shape with `prepend_batch_axis`\u001b[39;00m\n\u001b[1;32m    718\u001b[0m     \u001b[38;5;66;03m# # at-least2d\u001b[39;00m\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;66;03m# if tensor.ndim > 2:\u001b[39;00m\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;66;03m#     tensor = tensor.squeeze(0)\u001b[39;00m\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;66;03m# elif tensor.ndim < 2:\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;66;03m#     tensor = tensor[None, :]\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 1225 at dim 1 (got 324)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Users/ujan/opt/anaconda3/envs/x-transfer/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/Users/ujan/opt/anaconda3/envs/x-transfer/lib/python3.10/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/Users/ujan/opt/anaconda3/envs/x-transfer/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:61\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Users/ujan/opt/anaconda3/envs/x-transfer/lib/python3.10/site-packages/transformers/data/data_collator.py:249\u001b[0m, in \u001b[0;36mDataCollatorWithPadding.__call__\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m--> 249\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[1;32m    257\u001b[0m         batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/Users/ujan/opt/anaconda3/envs/x-transfer/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2985\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.pad\u001b[0;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, return_attention_mask, return_tensors, verbose)\u001b[0m\n\u001b[1;32m   2982\u001b[0m             batch_outputs[key] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   2983\u001b[0m         batch_outputs[key]\u001b[38;5;241m.\u001b[39mappend(value)\n\u001b[0;32m-> 2985\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBatchEncoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Users/ujan/opt/anaconda3/envs/x-transfer/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:210\u001b[0m, in \u001b[0;36mBatchEncoding.__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[1;32m    206\u001b[0m     n_sequences \u001b[38;5;241m=\u001b[39m encoding[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_sequences\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_sequences \u001b[38;5;241m=\u001b[39m n_sequences\n\u001b[0;32m--> 210\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Users/ujan/opt/anaconda3/envs/x-transfer/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:731\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverflowing_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    727\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    728\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to create tensor returning overflowing tokens of different lengths. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    729\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease see if a fast version of this tokenizer is available to have this feature available.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    730\u001b[0m             )\n\u001b[0;32m--> 731\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    732\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to create tensor, you should probably activate truncation and/or padding with\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    733\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpadding=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtruncation=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to have batched tensors with the same length. Perhaps your\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    734\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m features (`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` in this case) have excessive nesting (inputs type `list` where type `int` is\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    735\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expected).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    736\u001b[0m         )\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`true_dist` in this case) have excessive nesting (inputs type `list` where type `int` is expected)."
     ]
    }
   ],
   "source": [
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9c78623f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'][690]['true_dist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4245f8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['13', '13', '4', '13', '6', '13', '9', '9', '13', '12', '12', '9', '0']\n",
      "['13', '13', '4', '13', '6', '13', '9', '9', '13', '12', '12', '9', '0']\n",
      "['13', '13', '4', '13', '6', '13', '9', '9', '13', '12', '12', '9', '0']\n",
      "['13', '13', '4', '13', '6', '13', '9', '9', '13', '12', '12', '9', '0']\n",
      "['13', '13', '4', '13', '6', '13', '9', '9', '13', '12', '12', '9', '0']\n",
      "['2', '0', '4', '2', '6', '4']\n"
     ]
    }
   ],
   "source": [
    "for x in dataset1['test']:\n",
    "    head = x['head']\n",
    "    for h in head:\n",
    "        if h.isdigit():\n",
    "            if len(head) == int(h):\n",
    "                print(head)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd6fef1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e531d6f307e04a229eee275b3d92b7a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.filter(lambda example: all(h.isdigit() for h in example['head']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9f99c199",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in dataset['test']:\n",
    "    head = x['head']\n",
    "    for h in head:\n",
    "        if not h.isdigit():\n",
    "            #print('not digit')\n",
    "            #print(h)\n",
    "            print(head)\n",
    "            print(len(head))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "309d8e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f70b80f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d90fa658a7c4c63a5274e9f7c8dd1d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/249 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2', '10', '5', '5', '2', '9', '9', '9', '2', '0', '13', '13', '10', '17', '17', '17', '13', '23', '21', '21', '23', '23', '10', '10']\n",
      "24\n",
      "graph\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "dist matrix\n",
      "[[0. 1. 3. 3. 2. 3. 3. 3. 2. 2. 4. 4. 3. 5. 5. 5. 4. 4. 5. 5. 4. 4. 3. 3.]\n",
      " [1. 0. 2. 2. 1. 2. 2. 2. 1. 1. 3. 3. 2. 4. 4. 4. 3. 3. 4. 4. 3. 3. 2. 2.]\n",
      " [3. 2. 0. 2. 1. 4. 4. 4. 3. 3. 5. 5. 4. 6. 6. 6. 5. 5. 6. 6. 5. 5. 4. 4.]\n",
      " [3. 2. 2. 0. 1. 4. 4. 4. 3. 3. 5. 5. 4. 6. 6. 6. 5. 5. 6. 6. 5. 5. 4. 4.]\n",
      " [2. 1. 1. 1. 0. 3. 3. 3. 2. 2. 4. 4. 3. 5. 5. 5. 4. 4. 5. 5. 4. 4. 3. 3.]\n",
      " [3. 2. 4. 4. 3. 0. 2. 2. 1. 3. 5. 5. 4. 6. 6. 6. 5. 5. 6. 6. 5. 5. 4. 4.]\n",
      " [3. 2. 4. 4. 3. 2. 0. 2. 1. 3. 5. 5. 4. 6. 6. 6. 5. 5. 6. 6. 5. 5. 4. 4.]\n",
      " [3. 2. 4. 4. 3. 2. 2. 0. 1. 3. 5. 5. 4. 6. 6. 6. 5. 5. 6. 6. 5. 5. 4. 4.]\n",
      " [2. 1. 3. 3. 2. 1. 1. 1. 0. 2. 4. 4. 3. 5. 5. 5. 4. 4. 5. 5. 4. 4. 3. 3.]\n",
      " [2. 1. 3. 3. 2. 3. 3. 3. 2. 0. 2. 2. 1. 3. 3. 3. 2. 2. 3. 3. 2. 2. 1. 1.]\n",
      " [4. 3. 5. 5. 4. 5. 5. 5. 4. 2. 0. 2. 1. 3. 3. 3. 2. 4. 5. 5. 4. 4. 3. 3.]\n",
      " [4. 3. 5. 5. 4. 5. 5. 5. 4. 2. 2. 0. 1. 3. 3. 3. 2. 4. 5. 5. 4. 4. 3. 3.]\n",
      " [3. 2. 4. 4. 3. 4. 4. 4. 3. 1. 1. 1. 0. 2. 2. 2. 1. 3. 4. 4. 3. 3. 2. 2.]\n",
      " [5. 4. 6. 6. 5. 6. 6. 6. 5. 3. 3. 3. 2. 0. 2. 2. 1. 5. 6. 6. 5. 5. 4. 4.]\n",
      " [5. 4. 6. 6. 5. 6. 6. 6. 5. 3. 3. 3. 2. 2. 0. 2. 1. 5. 6. 6. 5. 5. 4. 4.]\n",
      " [5. 4. 6. 6. 5. 6. 6. 6. 5. 3. 3. 3. 2. 2. 2. 0. 1. 5. 6. 6. 5. 5. 4. 4.]\n",
      " [4. 3. 5. 5. 4. 5. 5. 5. 4. 2. 2. 2. 1. 1. 1. 1. 0. 4. 5. 5. 4. 4. 3. 3.]\n",
      " [4. 3. 5. 5. 4. 5. 5. 5. 4. 2. 4. 4. 3. 5. 5. 5. 4. 0. 3. 3. 2. 2. 1. 3.]\n",
      " [5. 4. 6. 6. 5. 6. 6. 6. 5. 3. 5. 5. 4. 6. 6. 6. 5. 3. 0. 2. 1. 3. 2. 4.]\n",
      " [5. 4. 6. 6. 5. 6. 6. 6. 5. 3. 5. 5. 4. 6. 6. 6. 5. 3. 2. 0. 1. 3. 2. 4.]\n",
      " [4. 3. 5. 5. 4. 5. 5. 5. 4. 2. 4. 4. 3. 5. 5. 5. 4. 2. 1. 1. 0. 2. 1. 3.]\n",
      " [4. 3. 5. 5. 4. 5. 5. 5. 4. 2. 4. 4. 3. 5. 5. 5. 4. 2. 3. 3. 2. 0. 1. 3.]\n",
      " [3. 2. 4. 4. 3. 4. 4. 4. 3. 1. 3. 3. 2. 4. 4. 4. 3. 1. 2. 2. 1. 1. 0. 2.]\n",
      " [3. 2. 4. 4. 3. 4. 4. 4. 3. 1. 3. 3. 2. 4. 4. 4. 3. 3. 4. 4. 3. 3. 2. 0.]]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 28\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# compute adj matrix\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistance_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Users/ujan/opt/anaconda3/envs/x-transfer/lib/python3.10/site-packages/datasets/dataset_dict.py:816\u001b[0m, in \u001b[0;36mDatasetDict.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_file_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    814\u001b[0m     cache_file_names \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m}\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DatasetDict(\n\u001b[0;32m--> 816\u001b[0m     {\n\u001b[1;32m    817\u001b[0m         k: dataset\u001b[38;5;241m.\u001b[39mmap(\n\u001b[1;32m    818\u001b[0m             function\u001b[38;5;241m=\u001b[39mfunction,\n\u001b[1;32m    819\u001b[0m             with_indices\u001b[38;5;241m=\u001b[39mwith_indices,\n\u001b[1;32m    820\u001b[0m             with_rank\u001b[38;5;241m=\u001b[39mwith_rank,\n\u001b[1;32m    821\u001b[0m             input_columns\u001b[38;5;241m=\u001b[39minput_columns,\n\u001b[1;32m    822\u001b[0m             batched\u001b[38;5;241m=\u001b[39mbatched,\n\u001b[1;32m    823\u001b[0m             batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m    824\u001b[0m             drop_last_batch\u001b[38;5;241m=\u001b[39mdrop_last_batch,\n\u001b[1;32m    825\u001b[0m             remove_columns\u001b[38;5;241m=\u001b[39mremove_columns,\n\u001b[1;32m    826\u001b[0m             keep_in_memory\u001b[38;5;241m=\u001b[39mkeep_in_memory,\n\u001b[1;32m    827\u001b[0m             load_from_cache_file\u001b[38;5;241m=\u001b[39mload_from_cache_file,\n\u001b[1;32m    828\u001b[0m             cache_file_name\u001b[38;5;241m=\u001b[39mcache_file_names[k],\n\u001b[1;32m    829\u001b[0m             writer_batch_size\u001b[38;5;241m=\u001b[39mwriter_batch_size,\n\u001b[1;32m    830\u001b[0m             features\u001b[38;5;241m=\u001b[39mfeatures,\n\u001b[1;32m    831\u001b[0m             disable_nullable\u001b[38;5;241m=\u001b[39mdisable_nullable,\n\u001b[1;32m    832\u001b[0m             fn_kwargs\u001b[38;5;241m=\u001b[39mfn_kwargs,\n\u001b[1;32m    833\u001b[0m             num_proc\u001b[38;5;241m=\u001b[39mnum_proc,\n\u001b[1;32m    834\u001b[0m             desc\u001b[38;5;241m=\u001b[39mdesc,\n\u001b[1;32m    835\u001b[0m         )\n\u001b[1;32m    836\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    837\u001b[0m     }\n\u001b[1;32m    838\u001b[0m )\n",
      "File \u001b[0;32m/Users/ujan/opt/anaconda3/envs/x-transfer/lib/python3.10/site-packages/datasets/dataset_dict.py:817\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_file_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    814\u001b[0m     cache_file_names \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m}\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DatasetDict(\n\u001b[1;32m    816\u001b[0m     {\n\u001b[0;32m--> 817\u001b[0m         k: \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdrop_last_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_last_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m            \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremove_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m            \u001b[49m\u001b[43mload_from_cache_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_from_cache_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_file_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_file_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwriter_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdisable_nullable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_nullable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    837\u001b[0m     }\n\u001b[1;32m    838\u001b[0m )\n",
      "File \u001b[0;32m/Users/ujan/opt/anaconda3/envs/x-transfer/lib/python3.10/site-packages/datasets/arrow_dataset.py:2826\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   2823\u001b[0m disable_tqdm \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mis_progress_bar_enabled()\n\u001b[1;32m   2825\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_proc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m num_proc \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 2826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2830\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2832\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2833\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop_last_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_last_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2834\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremove_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2835\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2836\u001b[0m \u001b[43m        \u001b[49m\u001b[43mload_from_cache_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_from_cache_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2837\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_file_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_file_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2838\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwriter_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2839\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable_nullable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_nullable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2842\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnew_fingerprint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_fingerprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable_tqdm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_tqdm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2845\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2846\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2848\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_cache_file_name\u001b[39m(cache_file_name, rank):\n",
      "File \u001b[0;32m/Users/ujan/opt/anaconda3/envs/x-transfer/lib/python3.10/site-packages/datasets/arrow_dataset.py:562\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    561\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 562\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    563\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m/Users/ujan/opt/anaconda3/envs/x-transfer/lib/python3.10/site-packages/datasets/arrow_dataset.py:529\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    522\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    524\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    527\u001b[0m }\n\u001b[1;32m    528\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 529\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    530\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    531\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m/Users/ujan/opt/anaconda3/envs/x-transfer/lib/python3.10/site-packages/datasets/fingerprint.py:480\u001b[0m, in \u001b[0;36mfingerprint_transform.<locals>._fingerprint.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m             validate_fingerprint(kwargs[fingerprint_name])\n\u001b[1;32m    478\u001b[0m \u001b[38;5;66;03m# Call actual function\u001b[39;00m\n\u001b[0;32m--> 480\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;66;03m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:  \u001b[38;5;66;03m# update after calling func so that the fingerprint doesn't change if the function fails\u001b[39;00m\n",
      "File \u001b[0;32m/Users/ujan/opt/anaconda3/envs/x-transfer/lib/python3.10/site-packages/datasets/arrow_dataset.py:3247\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, disable_tqdm, desc, cache_only)\u001b[0m\n\u001b[1;32m   3243\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m   3244\u001b[0m     \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mslice\u001b[39m(i, i \u001b[38;5;241m+\u001b[39m batch_size)\u001b[38;5;241m.\u001b[39mindices(input_dataset\u001b[38;5;241m.\u001b[39mnum_rows)))\n\u001b[1;32m   3245\u001b[0m )  \u001b[38;5;66;03m# Something simpler?\u001b[39;00m\n\u001b[1;32m   3246\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3247\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_same_num_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_indexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3251\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3252\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3253\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NumExamplesMismatchError:\n\u001b[1;32m   3254\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetTransformationNotAllowedError(\n\u001b[1;32m   3255\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3256\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "File \u001b[0;32m/Users/ujan/opt/anaconda3/envs/x-transfer/lib/python3.10/site-packages/datasets/arrow_dataset.py:3123\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[1;32m   3122\u001b[0m     additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[0;32m-> 3123\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[1;32m   3125\u001b[0m     processed_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   3126\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mkeys_to_format\n\u001b[1;32m   3127\u001b[0m     }\n",
      "Cell \u001b[0;32mIn[50], line 24\u001b[0m, in \u001b[0;36mdistance_map\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdist matrix\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(dist_matrix)\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "def distance_map(batch):\n",
    "    ids = batch['idx']\n",
    "    tokens = batch['tokens']\n",
    "    text = batch['text']\n",
    "    heads = batch['head']\n",
    "    \n",
    "    \n",
    "    batch_size = len(heads)\n",
    "    for b in range(batch_size):\n",
    "        head_list = heads[b]\n",
    "        print(head_list)\n",
    "        seq_len = len(head_list)\n",
    "        print(seq_len)\n",
    "        graph = np.zeros((seq_len, seq_len))\n",
    "        # populate adjacency matrix\n",
    "        for s in range(seq_len):\n",
    "            if head_list[s] != 0:\n",
    "                graph[s, int(head_list[s])-1] = 1\n",
    "        print('graph')\n",
    "        print(graph)\n",
    "        dist_matrix = floyd_warshall(csgraph=graph, directed=False, unweighted=True)\n",
    "        print('dist matrix')\n",
    "        print(dist_matrix)\n",
    "        raise\n",
    "\n",
    "    # compute adj matrix\n",
    "    \n",
    "dataset.map(distance_map, batched=True, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb7100aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 3., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07361ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0],\n",
       "       [1, 0, 1, 1, 0],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([\n",
    "    [0, 1, 0, 0, 0],\n",
    "    [1, 0, 1, 1, 0],\n",
    "    [0, 1, 0, 0, 0],\n",
    "    [0, 1, 0, 0, 1],\n",
    "    [0, 0, 0, 1, 0]\n",
    "])\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba746d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 2., 2., 3.],\n",
       "       [1., 0., 1., 1., 2.],\n",
       "       [2., 1., 0., 2., 3.],\n",
       "       [2., 1., 2., 0., 1.],\n",
       "       [3., 2., 3., 1., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_matrix = floyd_warshall(csgraph=a, directed=False, unweighted=True)\n",
    "dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0fd0b19d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 2., 2., 3.],\n",
       "       [1., 0., 1., 1., 2.],\n",
       "       [2., 1., 0., 2., 3.],\n",
       "       [2., 1., 2., 0., 1.],\n",
       "       [3., 2., 3., 1., 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_matrix = floyd_warshall(csgraph=graph, directed=False)\n",
    "dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "061d79df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 3., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = np.zeros((3, 3))\n",
    "graph[1,1] = 3\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5a9ce126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1., 1., 1.]), array([0., 0., 0.])]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ones(3)\n",
    "b = np.zeros(3)\n",
    "l = []\n",
    "l.append(a)\n",
    "l.append(b)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4befc234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b430b145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(l).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b5ce9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c6bf460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8207826816681233"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = stats.spearmanr([1, 2, 3, 4, 5], [5, 6, 7, 8, 7])\n",
    "res.statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8230d834",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 4\n",
    "s = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27750a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SignificanceResult(statistic=0.07630700778642936, pvalue=0.6885846533599633)\n",
      "SignificanceResult(statistic=0.11546162402669634, pvalue=0.5434694510154613)\n",
      "SignificanceResult(statistic=0.14616240266963293, pvalue=0.44088472389295175)\n",
      "SignificanceResult(statistic=0.012235817575083427, pvalue=0.9488325740980201)\n",
      "SignificanceResult(statistic=-0.1474972191323693, pvalue=0.43667732375833057)\n",
      "SignificanceResult(statistic=0.06251390433815351, pvalue=0.7427795641677637)\n",
      "SignificanceResult(statistic=-0.22358175750834258, pvalue=0.23495949078364692)\n",
      "SignificanceResult(statistic=0.10478309232480533, pvalue=0.5815962537668229)\n",
      "SignificanceResult(statistic=-0.3446051167964405, pvalue=0.06220090340541729)\n",
      "SignificanceResult(statistic=-0.20978865406006672, pvalue=0.2658489717443996)\n",
      "SignificanceResult(statistic=0.217797552836485, pvalue=0.24760667595245606)\n",
      "SignificanceResult(statistic=0.3041156840934371, pvalue=0.10228067785201178)\n",
      "SignificanceResult(statistic=0.07897664071190211, pvalue=0.6782581459823961)\n",
      "SignificanceResult(statistic=0.03270300333704116, pvalue=0.8637864591472519)\n",
      "SignificanceResult(statistic=-0.07408231368186874, pvalue=0.6972322835738773)\n",
      "SignificanceResult(statistic=0.24093437152391545, pvalue=0.19964260283906532)\n",
      "SignificanceResult(statistic=-0.4616240266963292, pvalue=0.01023315325971891)\n",
      "SignificanceResult(statistic=0.15016685205784203, pvalue=0.4283284912394979)\n",
      "SignificanceResult(statistic=0.14349276974416017, pvalue=0.4493650226110115)\n",
      "SignificanceResult(statistic=0.2800889877641824, pvalue=0.1338437882052016)\n",
      "SignificanceResult(statistic=0.06295884315906564, pvalue=0.7410107692024197)\n",
      "SignificanceResult(statistic=-0.2507230255839822, pvalue=0.18142632424948252)\n",
      "SignificanceResult(statistic=-0.057174638487208, pvalue=0.7641029227953104)\n",
      "SignificanceResult(statistic=-0.055394883203559515, pvalue=0.7712493167085641)\n",
      "SignificanceResult(statistic=0.2671857619577308, pvalue=0.15347789017549382)\n",
      "SignificanceResult(statistic=0.025583982202447165, pvalue=0.8932470798379044)\n",
      "SignificanceResult(statistic=0.03270300333704116, pvalue=0.8637864591472519)\n",
      "SignificanceResult(statistic=0.34371523915461627, pvalue=0.06292401947061307)\n",
      "SignificanceResult(statistic=-0.010456062291434927, pvalue=0.9562674588297169)\n",
      "SignificanceResult(statistic=0.32769744160177977, pvalue=0.07709656292801977)\n"
     ]
    }
   ],
   "source": [
    "preds = np.random.rand(b,s,s)\n",
    "labels = np.random.rand(b,s,s)\n",
    "\n",
    "for s_i in range(s):\n",
    "    res = stats.spearmanr(preds[0][s_i], labels[0][s_i], axis=1)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7fee3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2703003337041157"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "664b2218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.38064516,  1.        ,  0.30055617, -0.08787542,  0.17775306,\n",
       "       -0.12614016,  0.04382647,  0.13770857, -0.03804227, -0.36462736,\n",
       "        0.23604004, -0.41935484,  0.00333704, -0.243604  , -0.11813126,\n",
       "        0.3054505 , -0.04338154,  0.08209121, -0.04382647,  0.13414905,\n",
       "        0.0028921 ,  0.14660734,  0.08164627,  0.04204672, -0.29477197,\n",
       "       -0.22669633,  0.08520578, -0.08921023, -0.16974416, -0.33793103,\n",
       "       -0.17686318,  0.1621802 ,  0.11101224, -0.36462736, -0.06028921,\n",
       "       -0.04605117, -0.00111235, -0.10077864,  0.10211346, -0.1243604 ,\n",
       "        0.11590656,  0.13192436, -0.02157953,  0.22358176, -0.14883204,\n",
       "        0.34638487, -0.17730812,  0.06918799,  0.01802002, -0.05094549,\n",
       "        0.1461624 ,  0.06206897, -0.05183537,  0.00912125, -0.2080089 ,\n",
       "        0.02335929, -0.08342603,  0.18086763, -0.0625139 , -0.07007786])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.statistic[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f92a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
